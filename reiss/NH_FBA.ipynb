{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38520b3b",
   "metadata": {},
   "source": [
    "# NH 투자증권 빅데이터 경진대회\n",
    "\n",
    "# 주제명:\n",
    "\n",
    "### 팀명: Fine Bigdata Analysts (FBA)\n",
    "### 팀장: 구본우 (KAIST 산업및시스템공학과)\n",
    "### 팀원: 최인수 (KAIST 산업및시스템공학과)\n",
    "### 팀원: 고우성 (Yonsei University 경제학과 컴퓨터과학과)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edeb289",
   "metadata": {},
   "source": [
    "### Import Packages \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf920096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from scipy import stats\n",
    "from datetime import date, datetime\n",
    "import investpy\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c41840",
   "metadata": {},
   "source": [
    "### Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89366f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797776bc",
   "metadata": {},
   "source": [
    "### Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def most_frequent(list):\n",
    "    return max(set(list), key = list.count)\n",
    "\n",
    "def can_convert_to_int(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1bdc5",
   "metadata": {},
   "source": [
    "### Global Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974a9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = (\"cus_info\",\n",
    "            \"cus_account\")\n",
    "\n",
    "RAW_DATA1 = (\"kr_equity\",\n",
    "             \"os_equity\")\n",
    "\n",
    "DATA_PATH = (\"kr_equity\",\n",
    "             \"os_equity\",\n",
    "             \"cus_account\")\n",
    "\n",
    "DATA_PATH1 = (\"os_equity\",\n",
    "              \"cus_account\")\n",
    "\n",
    "DATA_PATH2 = (\"cus_account_R3\",\n",
    "              \"cus_assets_R1\",\n",
    "              \"kr_equity_R2\",\n",
    "              \"os_equity_R3\")\n",
    "\n",
    "DATA_PATH3 = (\"cus_account\",\n",
    "              \"cus_assets\",\n",
    "              \"kr_equity\",\n",
    "              \"os_equity\")\n",
    "\n",
    "DATA_PATH4 = (\"cus_account_R5\",\n",
    "              \"cus_assets_R5\",\n",
    "              \"kr_equity_R5\",\n",
    "              \"os_equity_R5\",\n",
    "              \"cus_info_R3\")\n",
    "\n",
    "ASSET_COLUMNS = (\"tot_aet_tld_rnd_202201\",\n",
    "                 \"tot_aet_tld_rnd_202202\",\n",
    "                 \"tot_aet_tld_rnd_202203\",\n",
    "                 \"tot_aet_tld_rnd_202204\",\n",
    "                 \"tot_aet_tld_rnd_202205\",\n",
    "                 \"tot_aet_tld_rnd_202206\")\n",
    "\n",
    "MODE_COLUMNS = (\"act_no\",\n",
    "                \"mts_mm_access_type\",\n",
    "                \"SEX_F\",\n",
    "                \"SEX_M\",\n",
    "                \"SEX_NA\",\n",
    "                \"cus_age_stn_cd\",\n",
    "                \"pft_amt_stn_cd\",\n",
    "                \"fst_act_opn_dt\",\n",
    "                \"LIFESTAGE_1\",\n",
    "                \"LIFESTAGE_2\",\n",
    "                \"LIFESTAGE_3\",\n",
    "                \"LIFESTAGE_4\",\n",
    "                \"LIFESTAGE_5\",\n",
    "                \"LIFESTAGE_6\",\n",
    "                \"LIFESTAGE_7\",\n",
    "                \"LIFESTAGE_8\",\n",
    "                \"LIFESTAGE_9\",\n",
    "                \"LIFESTAGE_10\",\n",
    "                \"LIFESTAGE_NA\",\n",
    "                \"tco_cus_grd_cd\",\n",
    "                \"tot_ivs_te_sgm_cd\",\n",
    "                \"HOLDINGS_TYPE_1.0\",\n",
    "                \"HOLDINGS_TYPE_2.0\",\n",
    "                \"HOLDINGS_TYPE_3.0\",\n",
    "                \"HOLDINGS_TYPE_4.0\",\n",
    "                \"HOLDINGS_TYPE_NA\",\n",
    "                \"loy_sgm_cd\",\n",
    "                \"SECTOR_1.0\",\n",
    "                \"SECTOR_2.0\",\n",
    "                \"SECTOR_3.0\",\n",
    "                \"SECTOR_4.0\",\n",
    "                \"SECTOR_5.0\",\n",
    "                \"SECTOR_6.0\",\n",
    "                \"SECTOR_7.0\",\n",
    "                \"SECTOR_8.0\",\n",
    "                \"SECTOR_9.0\",\n",
    "                \"SECTOR_10.0\",\n",
    "                \"SECTOR_11.0\",\n",
    "                \"SECTOR_12.0\",\n",
    "                \"SECTOR_13.0\",\n",
    "                \"SECTOR_14.0\",\n",
    "                \"SECTOR_15.0\",\n",
    "                \"SECTOR_16.0\")\n",
    "\n",
    "MAX_COLUMNS = (\"stk_pdt_hld_yn\",\n",
    "               \"ose_stk_pdt_hld_yn\",\n",
    "               \"mrz_pdt_tp_sgm_cd\",\n",
    "               \"mrz_mkt_dit_cd\",\n",
    "               \"aet_bse_stk_trd_tp_cd\",\n",
    "               \"bas_stk_trd_tp_cd\")\n",
    "\n",
    "DROP_COLUMNS = (\"stl_bse_itg_bnc_qty\",\n",
    "                \"stl_bse_fc_now_eal_amt\",\n",
    "                \"itg_byn_cns_qty\",\n",
    "                \"itg_sll_cns_qty\",\n",
    "                \"cns_bse_itg_bnc_qty\",\n",
    "                \"cns_bse_now_eal_amt\",\n",
    "                \"cns_bse_fc_now_eal_amt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725e92d",
   "metadata": {},
   "source": [
    "### Data Process Parent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34bad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess(object):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\", data_path1=\"\", data_path2=\"\", data_path3=\"\", data_path4=\"\",\n",
    "                 data_path5=\"\", data_path6=\"\", data_path7=\"\", data_path8=\"\", data_path9=\"\"):\n",
    "\n",
    "        if excel_or_csv == \"csv\":\n",
    "            self.df = pd.read_csv(data_path, sep=',', encoding='unicode_escape')\n",
    "            self.df_list = [self.df]\n",
    "            if data_path1 != \"\":\n",
    "                self.df1 = pd.read_csv(data_path1, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df1)\n",
    "            if data_path2 != \"\":\n",
    "                self.df2 = pd.read_csv(data_path2, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df2)\n",
    "            if data_path3 != \"\":\n",
    "                self.df3 = pd.read_csv(data_path3, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df3)\n",
    "            if data_path4 != \"\":\n",
    "                self.df4 = pd.read_csv(data_path4, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df4)\n",
    "            if data_path5 != \"\":\n",
    "                self.df5 = pd.read_csv(data_path5, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df5)\n",
    "            if data_path6 != \"\":\n",
    "                self.df6 = pd.read_csv(data_path6, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df6)\n",
    "            if data_path7 != \"\":\n",
    "                self.df7 = pd.read_csv(data_path7, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df7)\n",
    "            if data_path8 != \"\":\n",
    "                self.df8 = pd.read_csv(data_path8, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df8)\n",
    "            if data_path9 != \"\":\n",
    "                self.df9 = pd.read_csv(data_path9, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df9)\n",
    "        else:\n",
    "            self.df = pd.read_excel(data_path)\n",
    "            self.df_list = [self.df]\n",
    "            if data_path1 != \"\":\n",
    "                self.df1 = pd.read_excel(data_path1)\n",
    "                self.df_list.append(self.df1)\n",
    "            if data_path2 != \"\":\n",
    "                self.df2 = pd.read_excel(data_path2)\n",
    "                self.df_list.append(self.df2)\n",
    "            if data_path3 != \"\":\n",
    "                self.df3 = pd.read_excel(data_path3)\n",
    "                self.df_list.append(self.df3)\n",
    "            if data_path4 != \"\":\n",
    "                self.df4 = pd.read_excel(data_path4)\n",
    "                self.df_list.append(self.df4)\n",
    "            if data_path5 != \"\":\n",
    "                self.df5 = pd.read_excel(data_path5)\n",
    "                self.df_list.append(self.df5)\n",
    "            if data_path6 != \"\":\n",
    "                self.df6 = pd.read_excel(data_path6)\n",
    "                self.df_list.append(self.df6)\n",
    "            if data_path7 != \"\":\n",
    "                self.df7 = pd.read_excel(data_path7)\n",
    "                self.df_list.append(self.df7)\n",
    "            if data_path8 != \"\":\n",
    "                self.df8 = pd.read_excel(data_path8)\n",
    "                self.df_list.append(self.df8)\n",
    "            if data_path9 != \"\":\n",
    "                self.df9 = pd.read_excel(data_path9)\n",
    "                self.df_list.append(self.df9)\n",
    "\n",
    "        self.df_len = len(self.df)\n",
    "\n",
    "    # dfs: data frames\n",
    "    # dps: data paths\n",
    "    def export(self, dps, excel_or_csv=\"\"):\n",
    "        if len(dps) == len(self.dfs):\n",
    "\n",
    "            if excel_or_csv == \"csv\":\n",
    "                for i in range(len(self.dfs)):\n",
    "                    self.dfs[i].to_csv(dps[i])\n",
    "                print(\"Exported To:\", dps)\n",
    "\n",
    "            else:\n",
    "                for i in range(len(self.dfs)):\n",
    "                    self.dfs[i].to_excel(dps[i])\n",
    "                print(\"Exported To:\", dps)\n",
    "\n",
    "        else:\n",
    "            print(\"Incorrect Number of Data Paths\")\n",
    "            print(\"Data Paths: \", len(dps))\n",
    "            print(\"Data Frames: \", len(self.dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e49dc",
   "metadata": {},
   "source": [
    "### Data Process Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c64fb",
   "metadata": {},
   "source": [
    "#### Check if Each Customer Maps to Unique Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47341086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customerAccount(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = self.df[[\"cus_no\", \"act_no\"]]\n",
    "\n",
    "        memory = {}\n",
    "\n",
    "        for i in range(len(self.df)):\n",
    "            if self.df.loc[i][\"cus_no\"] not in memory:\n",
    "                memory[self.df.loc[i][\"cus_no\"]] = [self.df.loc[i][\"act_no\"]]\n",
    "            elif self.df.loc[i][\"cus_no\"] in memory:\n",
    "                if self.df.loc[i][\"act_no\"] not in memory[self.df.loc[i][\"cus_no\"]]:\n",
    "                    memory[self.df.loc[i][\"cus_no\"]].append(self.df.loc[i])\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "        self.df1[\"Customer\"] = [\"_\"] * len(memory)\n",
    "        self.df1[\"Account Number\"] = [\"_\"] * len(memory)\n",
    "\n",
    "        j = 0\n",
    "        for key, value in memory.items():\n",
    "            self.df1.at[j, \"Customer\"] = key\n",
    "            self.df1.at[j, \"Account Number\"] = len(value)\n",
    "            j += 1\n",
    "\n",
    "        for i in range(len(self.df1)):\n",
    "            if self.df1.loc[i][\"Account Number\"] != 1:\n",
    "                print(\"Not 1 Found\")\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228dcb67",
   "metadata": {},
   "source": [
    "#### Reorder Time Series Observations (Rows) in Chronological Order for each Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd3e2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chronological2(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, sort_by=\"bse_ym\"):\n",
    "        self.df_output = pd.DataFrame()\n",
    "        current_acc = \"\"\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_acc == \"\":\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                indicies = [0]\n",
    "            elif current_acc == self.df.loc[i][\"act_no\"]:\n",
    "                indicies.append(i)\n",
    "            elif current_acc != self.df.loc[i][\"act_no\"]:\n",
    "\n",
    "                self.df1 = pd.DataFrame()\n",
    "                self.df1 = self.df.iloc[indicies, :]\n",
    "                self.df1 = self.df1.sort_values(by=sort_by, ascending=True)\n",
    "                self.df_output = self.df_output.append(self.df1, ignore_index=True)\n",
    "\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                indicies = [i]\n",
    "\n",
    "            if i == self.df_len - 1:\n",
    "                self.df1 = pd.DataFrame()\n",
    "                self.df1 = self.df.iloc[indicies, :]\n",
    "                self.df1 = self.df1.sort_values(by=sort_by, ascending=True)\n",
    "                self.df_output = self.df_output.append(self.df1, ignore_index=True)\n",
    "\n",
    "        self.dfs = [self.df_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8ad3e",
   "metadata": {},
   "source": [
    "#### Map Y/N to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd19af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class yesNo(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, columns=[]):\n",
    "        for column in columns:\n",
    "            for i in range(self.df_len):\n",
    "                print(i)\n",
    "                if self.df.loc[i][column] == \"Y\":\n",
    "                    self.df.at[i, column] = 1\n",
    "                elif self.df.loc[i][column] == \"N\":\n",
    "                    self.df.at[i, column] = 0\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c194b",
   "metadata": {},
   "source": [
    "#### Check Number of Unique Currencies in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2faee778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uniqueFX(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column=\"\"):\n",
    "        unique_fx = []\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][column] not in unique_fx:\n",
    "                unique_fx.append(self.df.loc[i][column])\n",
    "\n",
    "        for i in range(len(self.df1)):\n",
    "            if self.df1.loc[i][column] not in unique_fx:\n",
    "                unique_fx.append(self.df1.loc[i][column])\n",
    "\n",
    "        for fx in unique_fx:\n",
    "            print(fx)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85dfb8",
   "metadata": {},
   "source": [
    "#### Rename Customers and Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdcf0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class renameCusAcc(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        current_cus = \"\"\n",
    "        current_acc = \"\"\n",
    "        j = 0\n",
    "        acc_dict = {}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_cus == \"\" and current_acc == \"\":\n",
    "                current_cus = self.df.loc[i][\"cus_no\"]\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                acc_dict[self.df.loc[i][\"act_no\"]] = \"acc_\" + str(j)\n",
    "\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "            elif current_cus == self.df.loc[i][\"cus_no\"] and current_acc == self.df.loc[i][\"act_no\"]:\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "            elif current_cus != self.df.loc[i][\"cus_no\"] and current_acc != self.df.loc[i][\"act_no\"]:\n",
    "                current_cus = self.df.loc[i][\"cus_no\"]\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "\n",
    "                j += 1\n",
    "\n",
    "                acc_dict[self.df.loc[i][\"act_no\"]] = \"acc_\" + str(j)\n",
    "\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "        return acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d7b94",
   "metadata": {},
   "source": [
    "#### Rename Accounts\n",
    "#### Drop Customers Since Each Account Observation Maps to a Unique Customer Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9444e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class renameCusAcc1(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, acc_dict={}):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = acc_dict[self.df.loc[i, \"act_no\"]]\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "\n",
    "class renameCusAcc2(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, acc_dict={}):\n",
    "        self.df.drop(\"cus_no\", axis=1, inplace=True)\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = acc_dict[self.df.loc[i, \"act_no\"]]\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d70c0e",
   "metadata": {},
   "source": [
    "#### One Hot Encode FX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "298c33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneHotFX(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df1 = pd.get_dummies(self.df.cur_cd, prefix='FX')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"cur_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6349239",
   "metadata": {},
   "source": [
    "#### Order Accounts Ascending for All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8b8cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accToNum(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, drop=\"\"):\n",
    "\n",
    "        if drop != \"\":\n",
    "            self.df = self.df.drop([drop], axis=1)\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = int(self.df.loc[i][\"act_no\"][4:])\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "\n",
    "class sortByAcc(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = self.df.sort_values(by=\"act_no\", ascending=True, kind=\"mergesort\")  # mergesort is stable\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8ff60",
   "metadata": {},
   "source": [
    "#### Remove Unnecessary Index Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f313402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dropUnnamed(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for column in self.df:\n",
    "            if \"Unnamed\" in column:\n",
    "                self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bae73",
   "metadata": {},
   "source": [
    "#### Aggregate Monthly Access Count to Representative Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c288daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class monthlyAccessCount(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            arr = list(str(self.df.loc[i][\"mts_mm_access_type\"]))\n",
    "\n",
    "            sum = 0\n",
    "            for j in arr:\n",
    "                sum += int(j)\n",
    "\n",
    "            self.df.at[i, \"mts_mm_access_type\"] = sum\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612f4c7",
   "metadata": {},
   "source": [
    "#### One Hot Encode Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "136a159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneHotSex(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        pd.set_option(\"display.max_columns\", None)\n",
    "        for i in range(self.df_len):\n",
    "\n",
    "            if self.df.loc[i][\"sex_dit_cd\"] == 1:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"M\"\n",
    "            elif self.df.loc[i][\"sex_dit_cd\"] == 2:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"F\"\n",
    "            elif self.df.loc[i][\"sex_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.sex_dit_cd, prefix='SEX')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"sex_dit_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50da45d",
   "metadata": {},
   "source": [
    "#### Set Age = 99 to \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c819c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class processAge(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"cus_age_stn_cd\"] == 99:\n",
    "                self.df.at[i, \"cus_age_stn_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb182403",
   "metadata": {},
   "source": [
    "#### Regroup Main Traded Security to Proxy for Customer Risk Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfc65fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class regroupSecurity(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        low_risk = [1, 15, 14, 13, 12, 11, 10]\n",
    "        mid_risk = [9, 8, 7, 6]\n",
    "        high_risk = [5, 4, 3, 2]\n",
    "        na = [99]\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in low_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 1\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in mid_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 2\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in high_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 3\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in na:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ac0cae",
   "metadata": {},
   "source": [
    "#### Set Lifestage = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e8230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lifestageProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"lsg_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"lsg_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.lsg_sgm_cd, prefix='LIFESTAGE')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"lsg_sgm_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4198eb",
   "metadata": {},
   "source": [
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6cfe755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customerLvlProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        dictionary = {1: 7,\n",
    "                      2: 6,\n",
    "                      3: 5,\n",
    "                      4: 4,\n",
    "                      5: 3,\n",
    "                      9: 2,\n",
    "                      99: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            self.df.at[i, \"tco_cus_grd_cd\"] = dictionary[self.df.loc[i][\"tco_cus_grd_cd\"]]\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf0991",
   "metadata": {},
   "source": [
    "#### Set Total Investing Duration = \"99\" to \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6abbeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class totalDurationInvestingProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"tot_ivs_te_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"tot_ivs_te_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b973d",
   "metadata": {},
   "source": [
    "#### Set Holdings Type = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1cc2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class holdingsTypeProcessing(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"hld_pdt_tp_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"hld_pdt_tp_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.hld_pdt_tp_sgm_cd, prefix='HOLDINGS_TYPE')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"hld_pdt_tp_sgm_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c7232",
   "metadata": {},
   "source": [
    "#### Set Loyalty = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86e45b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loyaltyProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 6,\n",
    "                      2: 5,\n",
    "                      3: 4,\n",
    "                      4: 3,\n",
    "                      5: 2,\n",
    "                      6: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"loy_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"loy_sgm_cd\"] in dictionary:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = dictionary[self.df.loc[i][\"loy_sgm_cd\"]]\n",
    "            else:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ae59e",
   "metadata": {},
   "source": [
    "#### Set Main Market = \"99\" to \"NA\"\n",
    "#### Regroup Main Market to Proxy for Customer Sophistication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c348ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mainMarketProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        low_soph = [6]\n",
    "        mid_soph = [1, 2, 4]\n",
    "        high_soph = [5]\n",
    "        vhigh_soph = [3]\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"mrz_mkt_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in low_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 1\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in mid_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 2\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in high_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 3\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in vhigh_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 4\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc807f",
   "metadata": {},
   "source": [
    "#### Set Main Sector = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d21fbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mainSectorProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"mrz_btp_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"mrz_btp_dit_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.mrz_btp_dit_cd, prefix='SECTOR')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"mrz_btp_dit_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da44b82",
   "metadata": {},
   "source": [
    "#### Set Net Worth = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca0d442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class netWorthProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 5,\n",
    "                      2: 4,\n",
    "                      3: 3,\n",
    "                      4: 2,\n",
    "                      5: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] == 99 or self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] == \"_\":\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] in dictionary:\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = dictionary[self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"]]\n",
    "            else:\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdd365",
   "metadata": {},
   "source": [
    "#### Set Trade Frequency = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9072a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tradeFrequencyProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 11,\n",
    "                      2: 10,\n",
    "                      3: 9,\n",
    "                      4: 8,\n",
    "                      5: 7,\n",
    "                      6: 6,\n",
    "                      7: 5,\n",
    "                      8: 4,\n",
    "                      9: 3,\n",
    "                      10: 2,\n",
    "                      11: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"bas_stk_trd_tp_cd\"] == 99:\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = \"NA\"\n",
    "            if can_convert_to_int(self.df.loc[i][\"bas_stk_trd_tp_cd\"]):\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = dictionary[int(self.df.loc[i][\"bas_stk_trd_tp_cd\"])]\n",
    "            else:\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c84501",
   "metadata": {},
   "source": [
    "#### Drop Column Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b104bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dropColumn(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"Unnamed\"):\n",
    "        self.df = self.df.drop([column_name], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09cf75",
   "metadata": {},
   "source": [
    "#### Time Series to Cross Sectional by Taking Max Asset Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77ec9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxAssetValue(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            arr = []\n",
    "            for column in ASSET_COLUMNS:\n",
    "                if can_convert_to_int(self.df.loc[i][column]):\n",
    "                    arr.append(self.df.loc[i][column])\n",
    "\n",
    "            self.df.at[i, \"MAX_ASSET_VALUE\"] = max(arr)\n",
    "\n",
    "        for column in ASSET_COLUMNS:\n",
    "            self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd23c1",
   "metadata": {},
   "source": [
    "#### Derive Account Lifespan from Account Open Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10141fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accLifespan(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        today = date.today()\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            year = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[0:4])\n",
    "            month = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[4:6])\n",
    "            day = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[6:8])\n",
    "\n",
    "            dateObject = date(year, month, day)\n",
    "\n",
    "            self.df.at[i, \"fst_act_opn_dt\"] = (today - dateObject).days\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda87ca",
   "metadata": {},
   "source": [
    "#### Time Series to Cross Sectional by taking the Mode, for Customer Information CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70dc1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class infoToCrossSectMode(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "\n",
    "        for column_name in MODE_COLUMNS:\n",
    "            current_acc = \"\"\n",
    "            k = 0\n",
    "            memory = []\n",
    "\n",
    "            for i in range(self.df_len):\n",
    "                print(column_name, i)\n",
    "\n",
    "                if current_acc == \"\":\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory = [self.df.loc[i][column_name]]\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "                if i == self.df_len - 1:\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ed602e",
   "metadata": {},
   "source": [
    "#### Time Series to Cross Sectional by taking Max, for Customer Information CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8b5b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class infoToCrossSectMax(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "\n",
    "        for column_name in MAX_COLUMNS:\n",
    "            current_acc = \"\"\n",
    "            k = 0\n",
    "            memory = []\n",
    "\n",
    "            for i in range(self.df_len):\n",
    "                print(column_name, i)\n",
    "\n",
    "                if current_acc == \"\":\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = max(memory)\n",
    "\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory = [self.df.loc[i][column_name]]\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "                if i == self.df_len - 1:\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18cc8e",
   "metadata": {},
   "source": [
    "#### Concatenate Two Data Frames Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25343e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class concatDataframes(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7bbbc",
   "metadata": {},
   "source": [
    "#### Concatenate Two Data Frames Class with Specific Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e70327a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class concatDataframes2(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"\"):\n",
    "        self.df1 = self.df1[[column_name]]\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9b225",
   "metadata": {},
   "source": [
    "#### Concatenate Two Data Frames Class with Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e039946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class concatAll(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, data_path2, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, data_path2=data_path2, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, path1_column=\"\", path2_column=\"\", path2_column1=\"\"):\n",
    "        self.df1 = self.df1[[path1_column]]\n",
    "        self.df2 = self.df2[[path2_column, path2_column1]]\n",
    "\n",
    "        self.df = pd.concat([self.df, self.df1, self.df2], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a6db4",
   "metadata": {},
   "source": [
    "#### Remove White Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b252717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class removeWhiteSpace(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"\"):\n",
    "        for i in range(self.df_len):\n",
    "\n",
    "            self.df.at[i, column_name] = str(self.df.loc[i][column_name]).strip()\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a55557",
   "metadata": {},
   "source": [
    "#### ISIN to Ticker using investpy Package\n",
    "#### 외부 데이터 사용:\n",
    "#### \"vol_3m\" Column: Standard Deviation of Daily Log Normal Price Returns with Historic 3 Month Rolling Window Annualized by a Factor of 250. Data Sourced Based on Date: 2020-12-31 to Avoid Look-ahead Bias. Data Sourced from S&P Capital IQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d21b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class getTicker(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"vol_3m\"] == \"_\":\n",
    "                print(i)\n",
    "                try:\n",
    "                    df = investpy.stocks.search_stocks(by='isin', value=str(self.df.loc[i][\"iem_cd\"]))\n",
    "                    ticker = df.loc[0]['symbol']\n",
    "                except:\n",
    "                    ticker = \"_\"\n",
    "\n",
    "                self.df.at[i, \"new_ticker\"] = ticker\n",
    "            else:\n",
    "                self.df.at[i, \"new_ticker\"] = \"__\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0db8d",
   "metadata": {},
   "source": [
    "#### Drop Uneccesary Columns in Account CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5830ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accountDrop(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for column in DROP_COLUMNS:\n",
    "            self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0293b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
