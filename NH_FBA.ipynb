{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7770390f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 주제명: Convoluted Autoencoder-based Dimension Reduced Sociodemographic Clustering of Digital Finance Customers\n",
    "# ^ 더 마땅한걸로 인수님이 바꿔주실 거라 생각합니다 ㅎㅎ\n",
    "\n",
    "### 팀명: Fine Bigdata Analysts (FBA)\n",
    "### 팀원1: 구본우 (KAIST 산업및시스템공학과)\n",
    "### 팀원2: 최인수 (KAIST 산업및시스템공학과)\n",
    "### 팀원3: 고우성 (Yonsei University 경제학과 컴퓨터과학과)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b55a08",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Packages \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0374a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from scipy import stats\n",
    "from datetime import date, datetime\n",
    "import investpy\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a479c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8552d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a389a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42952cbc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def isfloat(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def most_frequent(list):\n",
    "    return max(set(list), key = list.count)\n",
    "\n",
    "def can_convert_to_int(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d71783",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Global Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78bd67d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RAW_DATA = (\"cus_info\",\n",
    "            \"cus_account\")\n",
    "\n",
    "RAW_DATA1 = (\"kr_equity\",\n",
    "             \"os_equity\")\n",
    "\n",
    "DATA_PATH = (\"kr_equity\",\n",
    "             \"os_equity\",\n",
    "             \"cus_account\")\n",
    "\n",
    "DATA_PATH1 = (\"os_equity\",\n",
    "              \"cus_account\")\n",
    "\n",
    "DATA_PATH2 = (\"cus_account_R3\",\n",
    "              \"cus_assets_R1\",\n",
    "              \"kr_equity_R2\",\n",
    "              \"os_equity_R3\")\n",
    "\n",
    "DATA_PATH3 = (\"cus_account\",\n",
    "              \"cus_assets\",\n",
    "              \"kr_equity\",\n",
    "              \"os_equity\")\n",
    "\n",
    "DATA_PATH4 = (\"cus_account_R5\",\n",
    "              \"cus_assets_R5\",\n",
    "              \"kr_equity_R5\",\n",
    "              \"os_equity_R5\",\n",
    "              \"cus_info_R3\")\n",
    "\n",
    "ASSET_COLUMNS = (\"tot_aet_tld_rnd_202201\",\n",
    "                 \"tot_aet_tld_rnd_202202\",\n",
    "                 \"tot_aet_tld_rnd_202203\",\n",
    "                 \"tot_aet_tld_rnd_202204\",\n",
    "                 \"tot_aet_tld_rnd_202205\",\n",
    "                 \"tot_aet_tld_rnd_202206\")\n",
    "\n",
    "MODE_COLUMNS = (\"act_no\",\n",
    "                \"mts_mm_access_type\",\n",
    "                \"SEX_F\",\n",
    "                \"SEX_M\",\n",
    "                \"SEX_NA\",\n",
    "                \"cus_age_stn_cd\",\n",
    "                \"pft_amt_stn_cd\",\n",
    "                \"fst_act_opn_dt\",\n",
    "                \"LIFESTAGE_1\",\n",
    "                \"LIFESTAGE_2\",\n",
    "                \"LIFESTAGE_3\",\n",
    "                \"LIFESTAGE_4\",\n",
    "                \"LIFESTAGE_5\",\n",
    "                \"LIFESTAGE_6\",\n",
    "                \"LIFESTAGE_7\",\n",
    "                \"LIFESTAGE_8\",\n",
    "                \"LIFESTAGE_9\",\n",
    "                \"LIFESTAGE_10\",\n",
    "                \"LIFESTAGE_NA\",\n",
    "                \"tco_cus_grd_cd\",\n",
    "                \"tot_ivs_te_sgm_cd\",\n",
    "                \"HOLDINGS_TYPE_1.0\",\n",
    "                \"HOLDINGS_TYPE_2.0\",\n",
    "                \"HOLDINGS_TYPE_3.0\",\n",
    "                \"HOLDINGS_TYPE_4.0\",\n",
    "                \"HOLDINGS_TYPE_NA\",\n",
    "                \"loy_sgm_cd\",\n",
    "                \"SECTOR_1.0\",\n",
    "                \"SECTOR_2.0\",\n",
    "                \"SECTOR_3.0\",\n",
    "                \"SECTOR_4.0\",\n",
    "                \"SECTOR_5.0\",\n",
    "                \"SECTOR_6.0\",\n",
    "                \"SECTOR_7.0\",\n",
    "                \"SECTOR_8.0\",\n",
    "                \"SECTOR_9.0\",\n",
    "                \"SECTOR_10.0\",\n",
    "                \"SECTOR_11.0\",\n",
    "                \"SECTOR_12.0\",\n",
    "                \"SECTOR_13.0\",\n",
    "                \"SECTOR_14.0\",\n",
    "                \"SECTOR_15.0\",\n",
    "                \"SECTOR_16.0\")\n",
    "\n",
    "MAX_COLUMNS = (\"stk_pdt_hld_yn\",\n",
    "               \"ose_stk_pdt_hld_yn\",\n",
    "               \"mrz_pdt_tp_sgm_cd\",\n",
    "               \"mrz_mkt_dit_cd\",\n",
    "               \"aet_bse_stk_trd_tp_cd\",\n",
    "               \"bas_stk_trd_tp_cd\")\n",
    "\n",
    "DROP_COLUMNS = (\"stl_bse_itg_bnc_qty\",\n",
    "                \"stl_bse_fc_now_eal_amt\",\n",
    "                \"itg_byn_cns_qty\",\n",
    "                \"itg_sll_cns_qty\",\n",
    "                \"cns_bse_itg_bnc_qty\",\n",
    "                \"cns_bse_now_eal_amt\",\n",
    "                \"cns_bse_fc_now_eal_amt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910621ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Process Parent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ada20b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataProcess(object):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\", data_path1=\"\", data_path2=\"\", data_path3=\"\", data_path4=\"\",\n",
    "                 data_path5=\"\", data_path6=\"\", data_path7=\"\", data_path8=\"\", data_path9=\"\"):\n",
    "\n",
    "        if excel_or_csv == \"csv\":\n",
    "            self.df = pd.read_csv(data_path, sep=',', encoding='unicode_escape')\n",
    "            self.df_list = [self.df]\n",
    "            if data_path1 != \"\":\n",
    "                self.df1 = pd.read_csv(data_path1, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df1)\n",
    "            if data_path2 != \"\":\n",
    "                self.df2 = pd.read_csv(data_path2, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df2)\n",
    "            if data_path3 != \"\":\n",
    "                self.df3 = pd.read_csv(data_path3, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df3)\n",
    "            if data_path4 != \"\":\n",
    "                self.df4 = pd.read_csv(data_path4, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df4)\n",
    "            if data_path5 != \"\":\n",
    "                self.df5 = pd.read_csv(data_path5, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df5)\n",
    "            if data_path6 != \"\":\n",
    "                self.df6 = pd.read_csv(data_path6, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df6)\n",
    "            if data_path7 != \"\":\n",
    "                self.df7 = pd.read_csv(data_path7, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df7)\n",
    "            if data_path8 != \"\":\n",
    "                self.df8 = pd.read_csv(data_path8, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df8)\n",
    "            if data_path9 != \"\":\n",
    "                self.df9 = pd.read_csv(data_path9, sep=',', encoding='unicode_escape')\n",
    "                self.df_list.append(self.df9)\n",
    "        else:\n",
    "            self.df = pd.read_excel(data_path)\n",
    "            self.df_list = [self.df]\n",
    "            if data_path1 != \"\":\n",
    "                self.df1 = pd.read_excel(data_path1)\n",
    "                self.df_list.append(self.df1)\n",
    "            if data_path2 != \"\":\n",
    "                self.df2 = pd.read_excel(data_path2)\n",
    "                self.df_list.append(self.df2)\n",
    "            if data_path3 != \"\":\n",
    "                self.df3 = pd.read_excel(data_path3)\n",
    "                self.df_list.append(self.df3)\n",
    "            if data_path4 != \"\":\n",
    "                self.df4 = pd.read_excel(data_path4)\n",
    "                self.df_list.append(self.df4)\n",
    "            if data_path5 != \"\":\n",
    "                self.df5 = pd.read_excel(data_path5)\n",
    "                self.df_list.append(self.df5)\n",
    "            if data_path6 != \"\":\n",
    "                self.df6 = pd.read_excel(data_path6)\n",
    "                self.df_list.append(self.df6)\n",
    "            if data_path7 != \"\":\n",
    "                self.df7 = pd.read_excel(data_path7)\n",
    "                self.df_list.append(self.df7)\n",
    "            if data_path8 != \"\":\n",
    "                self.df8 = pd.read_excel(data_path8)\n",
    "                self.df_list.append(self.df8)\n",
    "            if data_path9 != \"\":\n",
    "                self.df9 = pd.read_excel(data_path9)\n",
    "                self.df_list.append(self.df9)\n",
    "\n",
    "        self.df_len = len(self.df)\n",
    "\n",
    "    # dfs: data frames\n",
    "    # dps: data paths\n",
    "    def export(self, dps, excel_or_csv=\"\"):\n",
    "        if len(dps) == len(self.dfs):\n",
    "\n",
    "            if excel_or_csv == \"csv\":\n",
    "                for i in range(len(self.dfs)):\n",
    "                    self.dfs[i].to_csv(dps[i])\n",
    "                print(\"Exported To:\", dps)\n",
    "\n",
    "            else:\n",
    "                for i in range(len(self.dfs)):\n",
    "                    self.dfs[i].to_excel(dps[i])\n",
    "                print(\"Exported To:\", dps)\n",
    "\n",
    "        else:\n",
    "            print(\"Incorrect Number of Data Paths\")\n",
    "            print(\"Data Paths: \", len(dps))\n",
    "            print(\"Data Frames: \", len(self.dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499d31e",
   "metadata": {},
   "source": [
    "## Data Processing Logic\n",
    "### After checking that each customer maps to a unique account, we map all other features based on customers' accounts. \n",
    "### We ensure that the machine learning algorithm does not learn spurious relationships due to the data. First, for all categorical data, we one hot encode them. Next, we appropriately handle non-available or \"99\" data points. Also, we handle symbolic numeric values such as \"mts_mm_access_type: 110000\" appropriately to proxy and represent the underlying feature. This is also the case for some dates.\n",
    "### We notice that there are some provided columns representing the same feature. We choose to omit the less accurate column for the column that best represents the customer's feature. We also omit features discretionarily through domain knowledge when we believe the signal(insight) to noise ratio is very low.\n",
    "### We discretionary group certain sets of values to proxy for a feature we believe is more meaningful than the non-processed column. This helps cluster the data into sociodemographic personas, which provides meaningful insight for customer targeting. \n",
    "### For intuitiveness, we reverse-order some numerically labeled features as we must look back at the features post-clustering.\n",
    "### We take a cross-sectional approach to our clustering instead of using a machine learning model suited for time-series. Therefore, we find an appropriate aggregation or representation method when transforming the time-series data into cross-sectional. We assume that six-month-month changes do not provide meaningful insight for a clustering algorithm. \n",
    "### We introduce new data in relation to existing observations and features, allowing us to create a new feature, \"Value Weighted Volatility\" that improves our understanding of the customers.\n",
    "### Lastly, we handle outliers and scale data through the MinMax approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add5a4c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Process Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497799b6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check if Each Customer Maps to Unique Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf81b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class customerAccount(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = self.df[[\"cus_no\", \"act_no\"]]\n",
    "\n",
    "        memory = {}\n",
    "\n",
    "        for i in range(len(self.df)):\n",
    "            if self.df.loc[i][\"cus_no\"] not in memory:\n",
    "                memory[self.df.loc[i][\"cus_no\"]] = [self.df.loc[i][\"act_no\"]]\n",
    "            elif self.df.loc[i][\"cus_no\"] in memory:\n",
    "                if self.df.loc[i][\"act_no\"] not in memory[self.df.loc[i][\"cus_no\"]]:\n",
    "                    memory[self.df.loc[i][\"cus_no\"]].append(self.df.loc[i])\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "        self.df1[\"Customer\"] = [\"_\"] * len(memory)\n",
    "        self.df1[\"Account Number\"] = [\"_\"] * len(memory)\n",
    "\n",
    "        j = 0\n",
    "        for key, value in memory.items():\n",
    "            self.df1.at[j, \"Customer\"] = key\n",
    "            self.df1.at[j, \"Account Number\"] = len(value)\n",
    "            j += 1\n",
    "\n",
    "        for i in range(len(self.df1)):\n",
    "            if self.df1.loc[i][\"Account Number\"] != 1:\n",
    "                print(\"Not 1 Found\")\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a26455",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Reorder Time Series Observations (Rows) in Chronological Order for each Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47578714",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class chronological2(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, sort_by=\"bse_ym\"):\n",
    "        self.df_output = pd.DataFrame()\n",
    "        current_acc = \"\"\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_acc == \"\":\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                indicies = [0]\n",
    "            elif current_acc == self.df.loc[i][\"act_no\"]:\n",
    "                indicies.append(i)\n",
    "            elif current_acc != self.df.loc[i][\"act_no\"]:\n",
    "\n",
    "                self.df1 = pd.DataFrame()\n",
    "                self.df1 = self.df.iloc[indicies, :]\n",
    "                self.df1 = self.df1.sort_values(by=sort_by, ascending=True)\n",
    "                self.df_output = self.df_output.append(self.df1, ignore_index=True)\n",
    "\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                indicies = [i]\n",
    "\n",
    "            if i == self.df_len - 1:\n",
    "                self.df1 = pd.DataFrame()\n",
    "                self.df1 = self.df.iloc[indicies, :]\n",
    "                self.df1 = self.df1.sort_values(by=sort_by, ascending=True)\n",
    "                self.df_output = self.df_output.append(self.df1, ignore_index=True)\n",
    "\n",
    "        self.dfs = [self.df_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44396917",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Map Y/N to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61ae24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class yesNo(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, columns=[]):\n",
    "        for column in columns:\n",
    "            for i in range(self.df_len):\n",
    "                print(i)\n",
    "                if self.df.loc[i][column] == \"Y\":\n",
    "                    self.df.at[i, column] = 1\n",
    "                elif self.df.loc[i][column] == \"N\":\n",
    "                    self.df.at[i, column] = 0\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21263b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Check Number of Unique Currencies in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79806a68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class uniqueFX(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column=\"\"):\n",
    "        unique_fx = []\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][column] not in unique_fx:\n",
    "                unique_fx.append(self.df.loc[i][column])\n",
    "\n",
    "        for i in range(len(self.df1)):\n",
    "            if self.df1.loc[i][column] not in unique_fx:\n",
    "                unique_fx.append(self.df1.loc[i][column])\n",
    "\n",
    "        for fx in unique_fx:\n",
    "            print(fx)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec081f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rename Customers and Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3dead",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class renameCusAcc(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        current_cus = \"\"\n",
    "        current_acc = \"\"\n",
    "        j = 0\n",
    "        acc_dict = {}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_cus == \"\" and current_acc == \"\":\n",
    "                current_cus = self.df.loc[i][\"cus_no\"]\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                acc_dict[self.df.loc[i][\"act_no\"]] = \"acc_\" + str(j)\n",
    "\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "            elif current_cus == self.df.loc[i][\"cus_no\"] and current_acc == self.df.loc[i][\"act_no\"]:\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "            elif current_cus != self.df.loc[i][\"cus_no\"] and current_acc != self.df.loc[i][\"act_no\"]:\n",
    "                current_cus = self.df.loc[i][\"cus_no\"]\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "\n",
    "                j += 1\n",
    "\n",
    "                acc_dict[self.df.loc[i][\"act_no\"]] = \"acc_\" + str(j)\n",
    "\n",
    "                self.df.at[i, \"cus_no\"] = \"cus_\" + str(j)\n",
    "                self.df.at[i, \"act_no\"] = \"acc_\" + str(j)\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "        return acc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b9723",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rename Accounts\n",
    "#### Drop Customers Since Each Account Observation Maps to a Unique Customer Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb806bd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class renameCusAcc1(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, acc_dict={}):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = acc_dict[self.df.loc[i, \"act_no\"]]\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "\n",
    "class renameCusAcc2(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, acc_dict={}):\n",
    "        self.df.drop(\"cus_no\", axis=1, inplace=True)\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = acc_dict[self.df.loc[i, \"act_no\"]]\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38203f9e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### One Hot Encode FX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f1c22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class oneHotFX(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df1 = pd.get_dummies(self.df.cur_cd, prefix='FX')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"cur_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877503e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Order Accounts Ascending for All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe6377",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class accToNum(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, drop=\"\"):\n",
    "\n",
    "        if drop != \"\":\n",
    "            self.df = self.df.drop([drop], axis=1)\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            self.df.at[i, \"act_no\"] = int(self.df.loc[i][\"act_no\"][4:])\n",
    "\n",
    "        self.dfs = [self.df]\n",
    "\n",
    "\n",
    "class sortByAcc(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = self.df.sort_values(by=\"act_no\", ascending=True, kind=\"mergesort\")  # mergesort is stable\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a9f26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remove Unnecessary Index Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ccc234",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class dropUnnamed(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for column in self.df:\n",
    "            if \"Unnamed\" in column:\n",
    "                self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b9b4c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Aggregate Monthly Access Count to Representative Integer\n",
    "#### e.g. “110000” → “2”, “111111” → “6”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b537b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class monthlyAccessCount(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            arr = list(str(self.df.loc[i][\"mts_mm_access_type\"]))\n",
    "\n",
    "            sum = 0\n",
    "            for j in arr:\n",
    "                sum += int(j)\n",
    "\n",
    "            self.df.at[i, \"mts_mm_access_type\"] = sum\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea82d73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### One Hot Encode Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc57abc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class oneHotSex(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        pd.set_option(\"display.max_columns\", None)\n",
    "        for i in range(self.df_len):\n",
    "\n",
    "            if self.df.loc[i][\"sex_dit_cd\"] == 1:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"M\"\n",
    "            elif self.df.loc[i][\"sex_dit_cd\"] == 2:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"F\"\n",
    "            elif self.df.loc[i][\"sex_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"sex_dit_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.sex_dit_cd, prefix='SEX')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"sex_dit_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774baaec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Age = 99 to \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d082f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class processAge(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"cus_age_stn_cd\"] == 99:\n",
    "                self.df.at[i, \"cus_age_stn_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0235ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Regroup Main Traded Security to Proxy for Customer Risk Profile\n",
    "#### 01 Low Risk = {ONLY_CMA, 신용대출, WRAP, MMW, 발행어음, RP, 신탁_퇴직연금}\n",
    "#### 02 Mid Risk = {ELS_DLS, 펀드, 국내채권, 해외채권}\n",
    "#### 03 High Risk = {국내주식, 해외주식, 선물옵션, 금속}\n",
    "#### NA = {99}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcae85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class regroupSecurity(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        low_risk = [1, 15, 14, 13, 12, 11, 10]\n",
    "        mid_risk = [9, 8, 7, 6]\n",
    "        high_risk = [5, 4, 3, 2]\n",
    "        na = [99]\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in low_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 1\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in mid_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 2\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in high_risk:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 3\n",
    "            elif self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] in na:\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44761c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Lifestage = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bde63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class lifestageProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"lsg_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"lsg_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.lsg_sgm_cd, prefix='LIFESTAGE')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"lsg_sgm_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aae439",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1cef57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class customerLvlProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        dictionary = {1: 7,\n",
    "                      2: 6,\n",
    "                      3: 5,\n",
    "                      4: 4,\n",
    "                      5: 3,\n",
    "                      9: 2,\n",
    "                      99: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            self.df.at[i, \"tco_cus_grd_cd\"] = dictionary[self.df.loc[i][\"tco_cus_grd_cd\"]]\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1256eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Total Investing Duration = \"99\" to \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148f437",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class totalDurationInvestingProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"tot_ivs_te_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"tot_ivs_te_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9527f84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Holdings Type = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ffda6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class holdingsTypeProcessing(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"hld_pdt_tp_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"hld_pdt_tp_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.hld_pdt_tp_sgm_cd, prefix='HOLDINGS_TYPE')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"hld_pdt_tp_sgm_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b237ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Loyalty = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94406f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class loyaltyProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 6,\n",
    "                      2: 5,\n",
    "                      3: 4,\n",
    "                      4: 3,\n",
    "                      5: 2,\n",
    "                      6: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"loy_sgm_cd\"] == 99:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"loy_sgm_cd\"] in dictionary:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = dictionary[self.df.loc[i][\"loy_sgm_cd\"]]\n",
    "            else:\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2120b8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Main Market = \"99\" to \"NA\"\n",
    "#### Regroup Main Market to Proxy for Customer Sophistication\n",
    "#### 01 Low Sophistication = {비매매}\n",
    "#### 02 Mid Sophistication = {거래소, 코스닥, 외화주식}\n",
    "#### 03 High Sophistication = {혼합}\n",
    "#### 04 Very High Sophistication = {ELW}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c64dc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class mainMarketProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        low_soph = [6]\n",
    "        mid_soph = [1, 2, 4]\n",
    "        high_soph = [5]\n",
    "        vhigh_soph = [3]\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"mrz_mkt_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in low_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 1\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in mid_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 2\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in high_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 3\n",
    "            elif self.df.loc[i][\"mrz_mkt_dit_cd\"] in vhigh_soph:\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 4\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799b88d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Main Sector = \"99\" to \"NA\"\n",
    "#### One Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbedbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class mainSectorProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"mrz_btp_dit_cd\"] == 99:\n",
    "                self.df.at[i, \"mrz_btp_dit_cd\"] = \"NA\"\n",
    "\n",
    "        self.df1 = pd.get_dummies(self.df.mrz_btp_dit_cd, prefix='SECTOR')\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.df.drop(\"mrz_btp_dit_cd\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29d9304",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Net Worth = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f488b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class netWorthProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 5,\n",
    "                      2: 4,\n",
    "                      3: 3,\n",
    "                      4: 2,\n",
    "                      5: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] == 99 or self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] == \"_\":\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = \"NA\"\n",
    "            elif self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] in dictionary:\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = dictionary[self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"]]\n",
    "            else:\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150dfba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Set Trade Frequency = \"99\" to \"NA\"\n",
    "#### Reverse Numerical Labeling for Intuitive Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1c74a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class tradeFrequencyProcess(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        dictionary = {1: 11,\n",
    "                      2: 10,\n",
    "                      3: 9,\n",
    "                      4: 8,\n",
    "                      5: 7,\n",
    "                      6: 6,\n",
    "                      7: 5,\n",
    "                      8: 4,\n",
    "                      9: 3,\n",
    "                      10: 2,\n",
    "                      11: 1}\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"bas_stk_trd_tp_cd\"] == 99:\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = \"NA\"\n",
    "            if can_convert_to_int(self.df.loc[i][\"bas_stk_trd_tp_cd\"]):\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = dictionary[int(self.df.loc[i][\"bas_stk_trd_tp_cd\"])]\n",
    "            else:\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = \"NA\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46e740",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Drop Column Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7891d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class dropColumn(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"Unnamed\"):\n",
    "        self.df = self.df.drop([column_name], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea74917",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Time Series to Cross Sectional by Taking Max Asset Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63add4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class maxAssetValue(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            arr = []\n",
    "            for column in ASSET_COLUMNS:\n",
    "                if can_convert_to_int(self.df.loc[i][column]):\n",
    "                    arr.append(self.df.loc[i][column])\n",
    "\n",
    "            self.df.at[i, \"MAX_ASSET_VALUE\"] = max(arr)\n",
    "\n",
    "        for column in ASSET_COLUMNS:\n",
    "            self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e40d9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Derive Account Lifespan from Account Open Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e31006",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class accLifespan(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        today = date.today()\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            year = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[0:4])\n",
    "            month = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[4:6])\n",
    "            day = int(str(self.df.loc[i][\"fst_act_opn_dt\"])[6:8])\n",
    "\n",
    "            dateObject = date(year, month, day)\n",
    "\n",
    "            self.df.at[i, \"fst_act_opn_dt\"] = (today - dateObject).days\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dbcb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Time Series to Cross Sectional by taking the Mode, for Customer Information CSV File\n",
    "#### cross_sectional = mode(time_series): \n",
    "\n",
    "#### {act_no 계좌번호(가명화), \n",
    "#### mts_mm_access_type MTS월단위접속패턴,\n",
    "#### sex_dit_cd 성별 (ONE HOT ENCODED),\n",
    "#### cus_age_stn_cd 연령대,\n",
    "#### pft_amt_stn_cd 수익금액구간코드,\n",
    "#### fst_act_opn_dt 최초계좌개설일,\n",
    "#### lsg_sgm_cd LIFESTAGE세그먼트코드 (ONE HOT ENCODED),\n",
    "#### tco_cus_grd_cd 고객등급코드,\n",
    "#### tot_ivs_te_sgm_cd 총투자기간세그먼트코드,\n",
    "#### hld_pdt_tp_sgm_cd 보유상품유형세그먼트코드 (ONE HOT ENCODED),\n",
    "#### loy_sgm_cd 충성도세그먼트코드,\n",
    "#### mrz_btp_dit_cd 주거래업종구분코드 (ONE HOT ENCODED)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952c3f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class infoToCrossSectMode(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "\n",
    "        for column_name in MODE_COLUMNS:\n",
    "            current_acc = \"\"\n",
    "            k = 0\n",
    "            memory = []\n",
    "\n",
    "            for i in range(self.df_len):\n",
    "                print(column_name, i)\n",
    "\n",
    "                if current_acc == \"\":\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory = [self.df.loc[i][column_name]]\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "                if i == self.df_len - 1:\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac07a10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Time Series to Cross Sectional by taking Max, for Customer Information CSV File\n",
    "#### cross_sectional = max(time_series):\n",
    " \n",
    "#### {stk_pdt_hld_yn 주식상품보유여부,\n",
    "#### ose_stk_pdt_hld_yn 해외주식상품보유여부,\n",
    "#### mrz_pdt_tp_sgm_cd 주거래상품군,\n",
    "#### mrz_mkt_dit_cd 주거래시장구분코드,\n",
    "#### aet_bse_stk_trd_tp_cd 자산기준주식거래유형코드,\n",
    "#### bas_stk_trd_tp_cd 기본주식거래유형코드}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0aaff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class infoToCrossSectMax(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        self.df1 = pd.DataFrame()\n",
    "\n",
    "        for column_name in MAX_COLUMNS:\n",
    "            current_acc = \"\"\n",
    "            k = 0\n",
    "            memory = []\n",
    "\n",
    "            for i in range(self.df_len):\n",
    "                print(column_name, i)\n",
    "\n",
    "                if current_acc == \"\":\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                    memory.append(self.df.loc[i][column_name])\n",
    "                elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = max(memory)\n",
    "\n",
    "                    current_acc = self.df.loc[i][\"act_no\"]\n",
    "                    memory = [self.df.loc[i][column_name]]\n",
    "\n",
    "                    k += 1\n",
    "\n",
    "                if i == self.df_len - 1:\n",
    "                    self.df1.at[k, \"act_no\"] = current_acc\n",
    "                    self.df1.at[k, column_name] = most_frequent(memory)\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b7da7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Concatenate Two Data Frames Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750dbaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class concatDataframes(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033509db",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Concatenate Two Data Frames Class with Specific Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e48a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class concatDataframes2(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"\"):\n",
    "        self.df1 = self.df1[[column_name]]\n",
    "        self.df = pd.concat([self.df, self.df1], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfa10b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Concatenate Two Data Frames Class with Specific Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bcded",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class concatAll(DataProcess):\n",
    "    def __init__(self, data_path, data_path1, data_path2, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, data_path1=data_path1, data_path2=data_path2, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, path1_column=\"\", path2_column=\"\", path2_column1=\"\"):\n",
    "        self.df1 = self.df1[[path1_column]]\n",
    "        self.df2 = self.df2[[path2_column, path2_column1]]\n",
    "\n",
    "        self.df = pd.concat([self.df, self.df1, self.df2], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f671f7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Remove White Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532eb3d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class removeWhiteSpace(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self, column_name=\"\"):\n",
    "        for i in range(self.df_len):\n",
    "\n",
    "            self.df.at[i, column_name] = str(self.df.loc[i][column_name]).strip()\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613f98f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ISIN to Ticker using investpy Package\n",
    "#### 외부 데이터 사용:\n",
    "#### \"vol_3m\" Column: Standard Deviation of Daily Log Normal Price Returns for Korean Securities with Historic 3 Month Rolling Window Annualized by a Factor of 250. Data Sourced Based on Date: 2020-12-31 to Avoid Look-ahead Bias. Data Sourced from S&P Capital IQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea270a5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class getTicker(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            if self.df.loc[i][\"vol_3m\"] == \"_\":\n",
    "                print(i)\n",
    "                try:\n",
    "                    df = investpy.stocks.search_stocks(by='isin', value=str(self.df.loc[i][\"iem_cd\"]))\n",
    "                    ticker = df.loc[0]['symbol']\n",
    "                except:\n",
    "                    ticker = \"_\"\n",
    "\n",
    "                self.df.at[i, \"new_ticker\"] = ticker\n",
    "            else:\n",
    "                self.df.at[i, \"new_ticker\"] = \"__\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebc627",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Drop Uneccesary Columns in Account CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00229",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class accountDrop(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for column in DROP_COLUMNS:\n",
    "            self.df = self.df.drop([column], axis=1)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d72ea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create \"final_vol_3m\" Column Which Combines \"vol_3m\" and \"new_vol_3m\"\n",
    "#### 외부 데이터 사용:\n",
    "#### \"new_vol_3m\" Column: Standard Deviation of Daily Log Normal Price Returns for Overseas Securities with Historic 3 Month Rolling Window Annualized by a Factor of 250. Data Sourced Based on Date: 2020-12-31 to Avoid Look-ahead Bias. Data Sourced from S&P Capital IQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3bebc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class finalVol3M(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if isfloat(self.df.loc[i][\"vol_3m\"]):\n",
    "                self.df.at[i, \"final_vol_3m\"] = self.df.loc[i][\"vol_3m\"]\n",
    "            elif isfloat(self.df.loc[i][\"new_vol_3m\"]):\n",
    "                self.df.at[i, \"final_vol_3m\"] = self.df.loc[i][\"new_vol_3m\"]\n",
    "            else:\n",
    "                self.df.at[i, \"final_vol_3m\"] = \"_\"\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850c90a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Derive Value Weighted Portfolio Volatility to Proxy for Customer Risk Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e76043",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class valueWeightedVolatility(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df1 = pd.DataFrame()\n",
    "        value_memory = []\n",
    "        volatility_memory = []\n",
    "\n",
    "        current_acc = \"\"\n",
    "        k = 0\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_acc == \"\":\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                if can_convert_to_int(self.df.loc[i][\"stl_bse_now_eal_amt\"]) and isfloat(self.df.loc[i][\"final_vol_3m\"]):\n",
    "                    value_memory.append(self.df.loc[i][\"stl_bse_now_eal_amt\"])\n",
    "                    volatility_memory.append(self.df.loc[i][\"final_vol_3m\"])\n",
    "            elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                if can_convert_to_int(self.df.loc[i][\"stl_bse_now_eal_amt\"]) and isfloat(self.df.loc[i][\"final_vol_3m\"]):\n",
    "                    value_memory.append(self.df.loc[i][\"stl_bse_now_eal_amt\"])\n",
    "                    volatility_memory.append(self.df.loc[i][\"final_vol_3m\"])\n",
    "            elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "                self.df1.at[k, \"act_no\"] = current_acc\n",
    "\n",
    "                if len(value_memory) > 0 and len(volatility_memory) > 0:\n",
    "                    weight_list = []\n",
    "                    sum = np.sum(value_memory)\n",
    "\n",
    "                    for value in value_memory:\n",
    "                        weight_list.append(value/sum)\n",
    "\n",
    "                    value_weighted_volatility = 0\n",
    "                    for j in range(len(volatility_memory)):\n",
    "                        value_weighted_volatility += float(volatility_memory[j]) * float(weight_list[j])\n",
    "\n",
    "                    self.df1.at[k, \"value_weighted_volatility\"] = value_weighted_volatility\n",
    "                else:\n",
    "                    self.df1.at[k, \"value_weighted_volatility\"] = \"_\"\n",
    "\n",
    "                value_memory = []\n",
    "                volatility_memory = []\n",
    "                if can_convert_to_int(self.df.loc[i][\"stl_bse_now_eal_amt\"]) and isfloat(self.df.loc[i][\"final_vol_3m\"]):\n",
    "                    value_memory.append(self.df.loc[i][\"stl_bse_now_eal_amt\"])\n",
    "                    volatility_memory.append(self.df.loc[i][\"final_vol_3m\"])\n",
    "\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                k += 1\n",
    "\n",
    "            if i == self.df_len - 1:\n",
    "                self.df1.at[k, \"act_no\"] = current_acc\n",
    "                if can_convert_to_int(self.df.loc[i][\"stl_bse_now_eal_amt\"]) and isfloat(self.df.loc[i][\"final_vol_3m\"]):\n",
    "                    value_memory.append(self.df.loc[i][\"stl_bse_now_eal_amt\"])\n",
    "                    volatility_memory.append(self.df.loc[i][\"final_vol_3m\"])\n",
    "\n",
    "                if len(value_memory) > 0 and len(volatility_memory) > 0:\n",
    "                    weight_list = []\n",
    "                    sum = np.sum(value_memory)\n",
    "\n",
    "                    for value in value_memory:\n",
    "                        weight_list.append(value / sum)\n",
    "\n",
    "                    value_weighted_volatility = 0\n",
    "                    for j in range(len(volatility_memory)):\n",
    "                        value_weighted_volatility += float(volatility_memory[j]) * float(weight_list[j])\n",
    "\n",
    "                    self.df1.at[k, \"value_weighted_volatility\"] = value_weighted_volatility\n",
    "                else:\n",
    "                    self.df1.at[k, \"value_weighted_volatility\"] = \"_\"\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e3650",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Aggregate Leverage for Each Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c68b8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class aggregateLeverage(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df1 = pd.DataFrame()\n",
    "        leverage = 0\n",
    "\n",
    "        current_acc = \"\"\n",
    "        k = 0\n",
    "\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if current_acc == \"\":\n",
    "                leverage += float(self.df.loc[i][\"lon_amt\"])\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "            elif self.df.loc[i][\"act_no\"] == current_acc:\n",
    "                leverage += float(self.df.loc[i][\"lon_amt\"])\n",
    "            elif self.df.loc[i][\"act_no\"] != current_acc:\n",
    "                self.df1.at[k, \"act_no\"] = current_acc\n",
    "                self.df1.at[k, \"leverage\"] = leverage\n",
    "\n",
    "                leverage = 0\n",
    "                current_acc = self.df.loc[i][\"act_no\"]\n",
    "                k += 1\n",
    "\n",
    "            if i == self.df_len - 1:\n",
    "                self.df1.at[k, \"act_no\"] = current_acc\n",
    "                self.df1.at[k, \"leverage\"] = leverage\n",
    "\n",
    "        self.dfs = [self.df1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abacf0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Drop Observations (Rows) with Missing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c10c53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class dropMissingData(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"cus_age_stn_cd\"] == \"_\":\n",
    "                self.df.drop(index=i, axis=0, inplace=True)\n",
    "                continue\n",
    "            if self.df.loc[i][\"tot_ivs_te_sgm_cd\"] == \"_\":\n",
    "                self.df.drop(index=i, axis=0, inplace=True)\n",
    "                continue\n",
    "            if self.df.loc[i][\"value_weighted_volatility\"] == \"_\" or self.df.loc[i][\"value_weighted_volatility\"] == 0 or self.df.loc[i][\"value_weighted_volatility\"] == \"0\":\n",
    "                self.df.drop(index=i, axis=0, inplace=True)\n",
    "                continue\n",
    "\n",
    "        self.df.reset_index(inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbde5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Process Observations (Rows) with Missing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d0134",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class processMissingData(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        for i in range(self.df_len):\n",
    "            print(i)\n",
    "            if self.df.loc[i][\"loy_sgm_cd\"] == \"_\":\n",
    "                self.df.at[i, \"loy_sgm_cd\"] = 1\n",
    "            if self.df.loc[i][\"mrz_pdt_tp_sgm_cd\"] == \"_\":\n",
    "                self.df.at[i, \"mrz_pdt_tp_sgm_cd\"] = 1\n",
    "            if self.df.loc[i][\"mrz_mkt_dit_cd\"] == \"_\":\n",
    "                self.df.at[i, \"mrz_mkt_dit_cd\"] = 1\n",
    "            if self.df.loc[i][\"aet_bse_stk_trd_tp_cd\"] == \"_\":\n",
    "                self.df.at[i, \"aet_bse_stk_trd_tp_cd\"] = 1\n",
    "            if self.df.loc[i][\"bas_stk_trd_tp_cd\"] == \"_\":\n",
    "                self.df.at[i, \"bas_stk_trd_tp_cd\"] = 1\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94203334",
   "metadata": {},
   "source": [
    "#### One Hot Encode Account Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneHotAccount(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        self.df1 = pd.get_dummies(self.df.act_no, prefix='ACCOUNT')\n",
    "        self.df = pd.concat([self.df1, self.df], axis=1)\n",
    "\n",
    "        self.df.drop(\"act_no\", axis=1, inplace=True)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d631f8e",
   "metadata": {},
   "source": [
    "#### MinMax Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edcd0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minMaxScale(DataProcess):\n",
    "    def __init__(self, data_path, excel_or_csv=\"\"):\n",
    "        super().__init__(data_path=data_path, excel_or_csv=excel_or_csv)\n",
    "\n",
    "    def process(self):\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        columns_list = []\n",
    "        for column in self.df:\n",
    "            columns_list.append(column)\n",
    "\n",
    "        self.df = pd.DataFrame(scaler.fit_transform(self.df), columns=columns_list)\n",
    "\n",
    "        self.dfs = [self.df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850ffb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Process Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf209f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process = customerAccount(data_path=\"cus_info.xlsx\")\n",
    "process.process()\n",
    "process.export([\"cus_acc.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295814b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in RAW_DATA:\n",
    "    process1 = chronological2(data_path=file_name + \".xlsx\")\n",
    "    process1.process(sort_by=\"bse_ym\")\n",
    "    process1.export([file_name + \"_R1.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e1d58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in RAW_DATA1:\n",
    "    process1 = chronological2(data_path=file_name + \".xlsx\")\n",
    "    process1.process(sort_by=\"orr_dt\")\n",
    "    process1.export([file_name + \"_R1.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa78b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process2 = yesNo(data_path=\"cus_info_R1\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process2.process(columns=[\"stk_pdt_hld_yn\", \"ose_stk_pdt_hld_yn\"])\n",
    "process2.export([\"cus_info\" + \"_R2.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b318b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process3 = uniqueFX(data_path=\"os_equity_R1.csv\", data_path1=\"cus_account_R1.csv\", excel_or_csv=\"csv\")\n",
    "process3.process(column=\"cur_cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f1b54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process4 = renameCusAcc(data_path=\"cus_info_R2.csv\", excel_or_csv=\"csv\")\n",
    "acc_dict = process4.process()\n",
    "process4.export([\"cus_info_R3.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e39b67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in DATA_PATH:\n",
    "    process5 = renameCusAcc1(data_path=file_name + \"_R1.csv\", excel_or_csv=\"csv\")\n",
    "    process5.process(acc_dict=acc_dict)\n",
    "    process5.export([file_name + \"_R2.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957efcda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process6 = renameCusAcc2(data_path=\"cus_assets.xlsx\")\n",
    "process6.process(acc_dict=acc_dict)\n",
    "process6.export([\"cus_assets_R1.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a7308",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in DATA_PATH1:\n",
    "    process7 = oneHotFX(data_path=file_name + \"_R2.csv\", excel_or_csv=\"csv\")\n",
    "    process7.process()\n",
    "    process7.export([file_name + \"_R3.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780463d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in DATA_PATH2:\n",
    "    process8 = accToNum(data_path=file_name + \".csv\", excel_or_csv=\"csv\")\n",
    "    process8.process()\n",
    "    process8.export([file_name[:-3] + \"_R4.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66bf87",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in DATA_PATH3:\n",
    "    process9 = sortByAcc(data_path=file_name + \"_R4.csv\", excel_or_csv=\"csv\")\n",
    "    process9.process()  # merge sort is used for stability\n",
    "    process9.export([file_name + \"_R5.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d39db5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in DATA_PATH4:\n",
    "    process10 = dropUnnamed(data_path=file_name + \".csv\", excel_or_csv=\"csv\")\n",
    "    process10.process()\n",
    "    process10.export([file_name[:-3] + \"_R6.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d39397",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process11 = accToNum(data_path=\"cus_info_R6\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process11.process(drop=\"cus_no\")\n",
    "process11.export([\"cus_info_R7.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628f82e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process12 = monthlyAccessCount(data_path=\"cus_info_R7\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process12.process()\n",
    "process12.export([\"cus_info_R8.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc371f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process13 = oneHotSex(data_path=\"cus_info_R8\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process13.process()\n",
    "process13.export([\"cus_info_R9.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8968ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process14 = processAge(data_path=\"cus_info_R9\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process14.process()\n",
    "process14.export([\"cus_info_R10.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46941f6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process15 = regroupSecurity(data_path=\"cus_info_R10\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process15.process()\n",
    "process15.export([\"cus_info_R11.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bf8af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process16 = lifestageProcess(data_path=\"cus_info_R11\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process16.process()\n",
    "process16.export([\"cus_info_R12.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d5127",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process17 = totalDurationInvestingProcess(data_path=\"cus_info_R13\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process17.process()\n",
    "process17.export([\"cus_info_R14.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498192fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process18 = holdingsTypeProcessing(data_path=\"cus_info_R14\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process18.process()\n",
    "process18.export([\"cus_info_R15.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a3c05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process19 = loyaltyProcess(data_path=\"cus_info_R15\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process19.process()\n",
    "process19.export([\"cus_info_R16.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5a89a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process20 = mainMarketProcess(data_path=\"cus_info_R16\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process20.process()\n",
    "process20.export([\"cus_info_R17.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57f294",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process21 = mainSectorProcess(data_path=\"cus_info_R17\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process21.process()\n",
    "process21.export([\"cus_info_R18.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3d5ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process22 = netWorthProcess(data_path=\"cus_info_R18\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process22.process()\n",
    "process22.export([\"cus_info_R19.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793aec3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process23 = tradeFrequencyProcess(data_path=\"cus_info_R19\" + \".csv\", excel_or_csv=\"csv\")\n",
    "process23.process()\n",
    "process23.export([\"cus_info_R20.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b2ca8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process24 = dropColumn(data_path=\"cus_assets_R6.csv\", excel_or_csv=\"csv\")\n",
    "process24.process(column_name=\"mts_mm_access_type\")\n",
    "process24.export([\"cus_assets_R7.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a996056",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process25 = dropColumn(data_path=\"cus_account_R6.csv\", excel_or_csv=\"csv\")\n",
    "process25.process(column_name=\"itg_pdt_tp_cd\")\n",
    "process25.export([\"cus_account_R7.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9fff9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process26 = maxAssetValue(data_path=\"cus_assets_R7.csv\", excel_or_csv=\"csv\")\n",
    "process26.process()\n",
    "process26.export([\"cus_assets_R8.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d52aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process27 = dropColumn(data_path=\"cus_info_R20.csv\", excel_or_csv=\"csv\")\n",
    "process27.process(column_name=\"cus_aet_stn_cd\")\n",
    "process27.export([\"cus_info_R21.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0ef676",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process28 = accLifespan(data_path=\"cus_info_R21.csv\", excel_or_csv=\"csv\")\n",
    "process28.process()\n",
    "process28.export([\"cus_info_R22.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b2b98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process29 = dropUnnamed(data_path=\"cus_info_R22.csv\", excel_or_csv=\"csv\")\n",
    "process29.process()\n",
    "process29.export([\"cus_info_R23.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d283ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process30 = infoToCrossSectMode(data_path=\"cus_info_R23.csv\", excel_or_csv=\"csv\")\n",
    "process30.process()\n",
    "process30.export([\"cus_info_R23_mode.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3222ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process31 = infoToCrossSectMax(data_path=\"cus_info_R23.csv\", excel_or_csv=\"csv\")\n",
    "process31.process()\n",
    "process31.export([\"cus_info_R23_max.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0585202",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process32 = concatDataframes(data_path=\"cus_info_R23_mode.csv\", data_path1=\"cus_info_R23_max.csv\", excel_or_csv=\"csv\")\n",
    "process32.process()\n",
    "process32.export([\"cus_info_R24.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30384364",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process33 = dropUnnamed(data_path=\"cus_info_R24.csv\", excel_or_csv=\"csv\")\n",
    "process33.process()\n",
    "process33.export([\"cus_info_R25.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82885fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process34 = dropColumn(data_path=\"cus_account_R7.csv\", excel_or_csv=\"csv\")\n",
    "process34.process(column_name=\"fc_sec_trd_nat_cd\")\n",
    "process34.export([\"cus_account_R8.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2699e04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process35 = removeWhiteSpace(data_path=\"cus_account_R8.csv\", excel_or_csv=\"csv\")\n",
    "process35.process(column_name=\"iem_cd\")\n",
    "process35.export([\"cus_account_R9.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc7cce",
   "metadata": {},
   "source": [
    "#### 외부 데이터 사용:\n",
    "#### cus_account_R10.xlsx is cus_account_R9.csv concatenated with new  column \"vol_3m\", where non-available data is \"_\"\n",
    "\n",
    "#### \"vol_3m\" Column: Standard Deviation of Daily Log Normal Price Returns for Korean Securities with Historic 3 Month Rolling Window Annualized by a Factor of 250. Data Sourced Based on Date: 2020-12-31 to Avoid Look-ahead Bias. Data Sourced from S&P Capital IQ.\n",
    "\n",
    "#### \"new_ticker\" Column: Security Ticker Data Sourced from investpy Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0e47c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process36 = getTicker(data_path=\"cus_account_R10.xlsx\")\n",
    "process36.process()\n",
    "process36.export([\"cus_account_R11.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6481099",
   "metadata": {},
   "source": [
    "#### 외부 데이터 사용:\n",
    "#### cus_account_R12.xlsx is cus_account_R11.csv concatenated with new  column \"new_vol_3m\", where non-available data is \"_\"\n",
    "\n",
    "#### \"new_vol_3m\" Column: Standard Deviation of Daily Log Normal Price Returns for Overseas Securities with Historic 3 Month Rolling Window Annualized by a Factor of 250. Data Sourced Based on Date: 2020-12-31 to Avoid Look-ahead Bias. Data Sourced from S&P Capital IQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6a7ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process37 = accountDrop(data_path=\"cus_account_R12.xlsx\")\n",
    "process37.process()\n",
    "process37.export([\"cus_account_R13.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887f4ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process38 = dropUnnamed(data_path=\"cus_account_R13.csv\", excel_or_csv=\"csv\")\n",
    "process38.process()\n",
    "process38.export([\"cus_account_R14.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead74f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process39 = finalVol3M(data_path=\"cus_account_R14.csv\", excel_or_csv=\"csv\")\n",
    "process39.process()\n",
    "process39.export([\"cus_account_R15.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37414289",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process40 = valueWeightedVolatility(data_path=\"cus_account_R15.csv\", excel_or_csv=\"csv\")\n",
    "process40.process()\n",
    "process40.export([\"cus_account_R16.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ab7b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process41 = aggregateLeverage(data_path=\"cus_account_R15.csv\", excel_or_csv=\"csv\")\n",
    "process41.process()\n",
    "process41.export([\"cus_account_R17.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92907ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "process42 = concatDataframes2(data_path=\"cus_account_R16.csv\", data_path1=\"cus_account_R17.csv\", excel_or_csv=\"csv\")\n",
    "process42.process(column_name=\"leverage\")\n",
    "process42.export([\"cus_account_R18.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "process43 = concatAll(data_path=\"cus_info_R25.csv\", data_path1=\"cus_assets_R8.csv\", data_path2=\"cus_account_R18.csv\", excel_or_csv=\"csv\")\n",
    "process43.process(path1_column=\"MAX_ASSET_VALUE\", path2_column=\"value_weighted_volatility\", path2_column1=\"leverage\")\n",
    "process43.export([\"all_R1.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88969ba5",
   "metadata": {},
   "source": [
    "#### All Empty (NaN) Cells in \"all_R1.csv\" are Replaced With \"_\" on Excel Due to Computational Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "process44 = dropColumn(data_path=\"all_R1.csv\", excel_or_csv=\"csv\")\n",
    "process44.process(column_name=\"SEX_NA\")\n",
    "process44.export([\"all_R2.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "process45 = dropColumn(data_path=\"all_R2.csv\", excel_or_csv=\"csv\")\n",
    "process45.process(column_name=\"LIFESTAGE_NA\")\n",
    "process45.export([\"all_R3.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e216def",
   "metadata": {},
   "outputs": [],
   "source": [
    "process46 = dropColumn(data_path=\"all_R3.csv\", excel_or_csv=\"csv\")\n",
    "process46.process(column_name=\"HOLDINGS_TYPE_NA\")\n",
    "process46.export([\"all_R4.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process47 = dropColumn(data_path=\"all_R4.csv\", excel_or_csv=\"csv\")\n",
    "process47.process(column_name=\"act_no.1\")\n",
    "process47.export([\"all_R5.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "process48 = dropMissingData(data_path=\"all_R5.csv\", excel_or_csv=\"csv\")\n",
    "process48.process()\n",
    "process48.export([\"all_R6.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "process49 = processMissingData(data_path=\"all_R6.csv\", excel_or_csv=\"csv\")\n",
    "process49.process()\n",
    "process49.export([\"all_R7.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "process50 = dropColumn(data_path=\"all_R7.csv\", excel_or_csv=\"csv\")\n",
    "process50.process(column_name=\"index\")\n",
    "process50.export([\"all_R8.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46413be",
   "metadata": {},
   "outputs": [],
   "source": [
    "process51 = dropUnnamed(data_path=\"all_R8.csv\", excel_or_csv=\"csv\")\n",
    "process51.process()\n",
    "process51.export([\"all_R9.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f98b27",
   "metadata": {},
   "source": [
    "### Manually Changed due to Computational Inefficiency\n",
    "#### mts_mm_access_type → access_count\n",
    "#### cus_age_stn_cd → age_group\n",
    "#### pft_amt_stn_cd → income_group\n",
    "#### fst_act_opn_dt → account_age\n",
    "#### tco_cus_grd_cd → nh_level\n",
    "#### tot_ivs_te_sgm_cd → invest_exp_group\n",
    "#### loy_sgm_cd → loyalty\n",
    "#### stk_pdt_hld_yn → kr_stock_yn\n",
    "#### ose_stk_pdt_hld_yn → overseas_stock_yn\n",
    "#### mrz_pdt_tp_sgm_cd → risk_tolerance\n",
    "#### mrz_mkt_dit_cd → sophistication\n",
    "#### aet_bse_stk_trd_tp_cd → stock_wealth_level\n",
    "#### bas_stk_trd_tp_cd → trading_frequency\n",
    "#### MAX_ASSET_VALUE → peak_asset_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee5c09",
   "metadata": {},
   "source": [
    "### Outlier Removal: R10: Removed Observations (Accounts) in Top 0.1% of Peak Assets and/or Top 0.1%  of Leverage Through Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b150b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process52 = oneHotAccount(data_path=\"all_R10.csv\", excel_or_csv=\"csv\")\n",
    "process52.process()\n",
    "process52.export([\"all_R11.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process53 = minMaxScale(data_path=\"all_R11.csv\", excel_or_csv=\"csv\")\n",
    "process53.process()\n",
    "process53.export([\"all_R12.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc21315",
   "metadata": {},
   "outputs": [],
   "source": [
    "process54 = dropUnnamed(data_path=\"all_R12.csv\", excel_or_csv=\"csv\")\n",
    "process54.process()\n",
    "process54.export([\"all_R13.csv\"], excel_or_csv=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f08de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
